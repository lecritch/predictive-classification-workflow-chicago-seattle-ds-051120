{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from sklearn.impute import MissingIndicator, SimpleImputer\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# plot_confusion_matrix is a handy visual tool, added in the latest version of scikit-learn\n",
    "# if you are running an older version, comment out this line and just use confusion_matrix\n",
    "# from sklearn.metrics import plot_confusion_matrix - this makes a nice coloured plot\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Steps\n",
    "\n",
    "1. Build a model based on the [Titanic dataset](https://www.kaggle.com/c/titanic/data) that predicts whether a given person survived or not\n",
    "2. Evaluate the performance of the model\n",
    "3. Make changes in an attempt to improve the model\n",
    "4. Demonstrate whether an improvement was made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "This dataset has the following columns:\n",
    "\n",
    "| Variable | Definition | Key |\n",
    "| -------- | ---------- | --- |\n",
    "| survival | Survival | 0 = No, 1 = Yes |\n",
    "| pclass | Ticket class | 1 = 1st, 2 = 2nd, 3 = 3rd |\n",
    "| sex | Sex | |\n",
    "| Age | Age in years | |\n",
    "| sibsp | # of siblings / spouses aboard the Titanic | |\n",
    "| parch | # of parents / children aboard the Titanic | |\n",
    "| ticket | Ticket number | |\n",
    "| fare | Passenger fare | |\n",
    "| cabin | Cabin number | |\n",
    "| embarked | Port of Embarkation | C = Cherbourg, Q = Queenstown, S = Southampton |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Understanding and Preparation\n",
    "\n",
    "Open up the file, get everything into `X` features and `y` target variables, divided into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age data is missing for about 1 in 9 rows in our dataset.  For now, let's just exclude it, plus the non-numeric columns, and `PassengerId` which doesn't seem like a real feature, but rather just an artifact of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"PassengerId\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pclass are numbers but it's not clear that the difference between 1st and 2nd is the\n",
    "# same as the difference between 2nd and 3rd\n",
    "numeric_columns = [\"Survived\", \"SibSp\", \"Parch\", \"Fare\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.pairplot(df[numeric_columns]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df[numeric_columns]\n",
    "X = numeric_df.drop(\"Survived\", axis=1)\n",
    "y = numeric_df[\"Survived\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Let's start with a completely \"dummy\" model, that will always choose the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = DummyClassifier(strategy=\"most_frequent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=None, strategy='most_frequent')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should expect all predictions to be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just grabbing the first 50 to save space\n",
    "dummy_model.predict(X_train)[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62331839, 0.62331839, 0.62612613])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(dummy_model, X_train, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the mean accuracy is a little over 62% if we always guess the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-33974e300a12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dummy Model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"plasma\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_confusion_matrix' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.suptitle(\"Dummy Model\")\n",
    "\n",
    "plot_confusion_matrix(dummy_model, X_train, y_train, ax=ax, cmap=\"plasma\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[417,   0],\n",
       "       [251,   0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just the numbers (this should work even with older scikit-learn)\n",
    "confusion_matrix(y_train, dummy_model.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pretty lopsided confusion matrix!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling, Again\n",
    "\n",
    "Let's use a logistic regression and compare its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_logreg_model = LogisticRegression(random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=2020, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_logreg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_logreg_model.predict(X_train)[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mixture of 1s and 0s this time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation, Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.68161435, 0.69955157, 0.67567568])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(simple_logreg_model, X_train, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the mean accuracy is closer to 70% if the model is actually taking in information from the features instead of always guessing the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.suptitle(\"Logistic Regression with Numeric Features Only\")\n",
    "\n",
    "plot_confusion_matrix(simple_logreg_model, X_train, y_train, ax=ax, cmap=\"plasma\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[390,  27],\n",
       "       [180,  71]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, simple_logreg_model.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in general we are not labeling many of the \"not survived\" passengers as \"survived\", but for \"survived\" passengers we're getting it right only about half of the time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation, Again\n",
    "\n",
    "Maybe there is some useful information in the features we are not using yet.  Let's go wild and add all of them!\n",
    "\n",
    "Note: you can and should add features incrementally in a \"real\" modeling context.  The engineering effort of encoding the variables can be non-trivial!  But here let's assume that it's not too much work to encode all of them.\n",
    "\n",
    "Start with a new train-test split that contains all of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Survived\", axis=1)\n",
    "y = df[\"Survived\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare',\n",
       "       'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass        0\n",
       "Name          0\n",
       "Sex           0\n",
       "Age         123\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Ticket        0\n",
       "Fare          0\n",
       "Cabin       516\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values\n",
    "\n",
    "Let's be extra cautious and make a separate column to indicate whether there originally was a missing value\n",
    "\n",
    "In our training data there are only missing values for a couple of the columns, but we can't be sure about where the test set will be missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MissingIndicator(error_on_new=True, features='all', missing_values=nan,\n",
       "                 sparse='auto')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicator = MissingIndicator(features=\"all\")\n",
    "indicator.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_indicator_columns(X, indicator):\n",
    "    \"\"\"\n",
    "    Helper function for transforming features\n",
    "    \n",
    "    For every feature in X, create another feature indicating whether that feature\n",
    "    is missing.  This doubles the number of columns in X.\n",
    "    \"\"\"\n",
    "    \n",
    "    # create a 2D array of True and False values indicating whether a given feature\n",
    "    # is missing for that row\n",
    "    missing_array_bool = indicator.transform(X)\n",
    "    \n",
    "    # transform into 1 and 0 for modeling\n",
    "    missing_array_int = missing_array_bool.astype(int)\n",
    "    \n",
    "    # helpful for readability but not needed for modeling\n",
    "    missing_column_names = [col + \"_missing\" for col in X.columns]\n",
    "    \n",
    "    # convert to df so it we can concat with X\n",
    "    missing_df = pd.DataFrame(missing_array_int, columns=missing_column_names, index=X.index)\n",
    "    \n",
    "    return pd.concat([X, missing_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = add_missing_indicator_columns(X_train, indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Pclass_missing</th>\n",
       "      <th>Name_missing</th>\n",
       "      <th>Sex_missing</th>\n",
       "      <th>Age_missing</th>\n",
       "      <th>SibSp_missing</th>\n",
       "      <th>Parch_missing</th>\n",
       "      <th>Ticket_missing</th>\n",
       "      <th>Fare_missing</th>\n",
       "      <th>Cabin_missing</th>\n",
       "      <th>Embarked_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>3</td>\n",
       "      <td>Yasbeck, Mr. Antoni</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2659</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>359</td>\n",
       "      <td>3</td>\n",
       "      <td>Mockler, Miss. Helen Mary \"Ellie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330980</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>McGough, Mr. James Robert</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17473</td>\n",
       "      <td>26.2875</td>\n",
       "      <td>E25</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>738</td>\n",
       "      <td>3</td>\n",
       "      <td>Ivanoff, Mr. Kanio</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349201</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>3</td>\n",
       "      <td>Gheorgheff, Mr. Stanio</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349254</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass                               Name     Sex   Age  SibSp  Parch  \\\n",
       "620       3                Yasbeck, Mr. Antoni    male  27.0      1      0   \n",
       "359       3  Mockler, Miss. Helen Mary \"Ellie\"  female   NaN      0      0   \n",
       "512       1          McGough, Mr. James Robert    male  36.0      0      0   \n",
       "738       3                 Ivanoff, Mr. Kanio    male   NaN      0      0   \n",
       "420       3             Gheorgheff, Mr. Stanio    male   NaN      0      0   \n",
       "\n",
       "       Ticket     Fare Cabin Embarked  Pclass_missing  Name_missing  \\\n",
       "620      2659  14.4542   NaN        C               0             0   \n",
       "359    330980   7.8792   NaN        Q               0             0   \n",
       "512  PC 17473  26.2875   E25        S               0             0   \n",
       "738    349201   7.8958   NaN        S               0             0   \n",
       "420    349254   7.8958   NaN        C               0             0   \n",
       "\n",
       "     Sex_missing  Age_missing  SibSp_missing  Parch_missing  Ticket_missing  \\\n",
       "620            0            0              0              0               0   \n",
       "359            0            1              0              0               0   \n",
       "512            0            0              0              0               0   \n",
       "738            0            1              0              0               0   \n",
       "420            0            1              0              0               0   \n",
       "\n",
       "     Fare_missing  Cabin_missing  Embarked_missing  \n",
       "620             0              1                 0  \n",
       "359             0              1                 0  \n",
       "512             0              0                 0  \n",
       "738             0              1                 0  \n",
       "420             0              1                 0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've specified which values were originally missing, let's fill in those missing values.  This takes two separate imputers because we want to use the mean for numeric data and the majority class for categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feature_names = [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "categorical_feature_names = [\"Pclass\", \"Name\", \"Sex\", \"Ticket\", \"Cabin\", \"Embarked\"]\n",
    "\n",
    "X_train_numeric = X_train[numeric_feature_names]\n",
    "X_train_categorical = X_train[categorical_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "              missing_values=nan, strategy='mean', verbose=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_imputer = SimpleImputer()\n",
    "numeric_imputer.fit(X_train_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "              missing_values=nan, strategy='most_frequent', verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "categorical_imputer.fit(X_train_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_values(X, imputer):\n",
    "    \"\"\"\n",
    "    Given a DataFrame and an imputer, use the imputer to fill in all\n",
    "    missing values in the DataFrame\n",
    "    \"\"\"\n",
    "    imputed_array = imputer.transform(X)\n",
    "    imputed_df = pd.DataFrame(imputed_array, columns=X.columns, index=X.index)\n",
    "    return imputed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_numeric = impute_missing_values(X_train_numeric, numeric_imputer)\n",
    "X_train_categorical = impute_missing_values(X_train_categorical, categorical_imputer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-check to make sure that all of the missing values are gone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age         0\n",
       "SibSp       0\n",
       "Parch       0\n",
       "Fare        0\n",
       "Pclass      0\n",
       "Name        0\n",
       "Sex         0\n",
       "Ticket      0\n",
       "Cabin       0\n",
       "Embarked    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_imputed = pd.concat([X_train_numeric, X_train_categorical], axis=1)\n",
    "X_train_imputed.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop all of the old columns from X_train, then concat the new imputed ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(numeric_feature_names + categorical_feature_names, axis=1)\n",
    "X_train = pd.concat([X_train_imputed, X_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Pclass_missing</th>\n",
       "      <th>Name_missing</th>\n",
       "      <th>Sex_missing</th>\n",
       "      <th>Age_missing</th>\n",
       "      <th>SibSp_missing</th>\n",
       "      <th>Parch_missing</th>\n",
       "      <th>Ticket_missing</th>\n",
       "      <th>Fare_missing</th>\n",
       "      <th>Cabin_missing</th>\n",
       "      <th>Embarked_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>3</td>\n",
       "      <td>Yasbeck, Mr. Antoni</td>\n",
       "      <td>male</td>\n",
       "      <td>2659</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>359</td>\n",
       "      <td>29.927982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>3</td>\n",
       "      <td>Mockler, Miss. Helen Mary \"Ellie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>330980</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>McGough, Mr. James Robert</td>\n",
       "      <td>male</td>\n",
       "      <td>PC 17473</td>\n",
       "      <td>E25</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>738</td>\n",
       "      <td>29.927982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>3</td>\n",
       "      <td>Ivanoff, Mr. Kanio</td>\n",
       "      <td>male</td>\n",
       "      <td>349201</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>29.927982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>3</td>\n",
       "      <td>Gheorgheff, Mr. Stanio</td>\n",
       "      <td>male</td>\n",
       "      <td>349254</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Age  SibSp  Parch     Fare Pclass  \\\n",
       "620  27.000000    1.0    0.0  14.4542      3   \n",
       "359  29.927982    0.0    0.0   7.8792      3   \n",
       "512  36.000000    0.0    0.0  26.2875      1   \n",
       "738  29.927982    0.0    0.0   7.8958      3   \n",
       "420  29.927982    0.0    0.0   7.8958      3   \n",
       "\n",
       "                                  Name     Sex    Ticket    Cabin Embarked  \\\n",
       "620                Yasbeck, Mr. Antoni    male      2659  B96 B98        C   \n",
       "359  Mockler, Miss. Helen Mary \"Ellie\"  female    330980  B96 B98        Q   \n",
       "512          McGough, Mr. James Robert    male  PC 17473      E25        S   \n",
       "738                 Ivanoff, Mr. Kanio    male    349201  B96 B98        S   \n",
       "420             Gheorgheff, Mr. Stanio    male    349254  B96 B98        C   \n",
       "\n",
       "     Pclass_missing  Name_missing  Sex_missing  Age_missing  SibSp_missing  \\\n",
       "620               0             0            0            0              0   \n",
       "359               0             0            0            1              0   \n",
       "512               0             0            0            0              0   \n",
       "738               0             0            0            1              0   \n",
       "420               0             0            0            1              0   \n",
       "\n",
       "     Parch_missing  Ticket_missing  Fare_missing  Cabin_missing  \\\n",
       "620              0               0             0              1   \n",
       "359              0               0             0              1   \n",
       "512              0               0             0              0   \n",
       "738              0               0             0              1   \n",
       "420              0               0             0              1   \n",
       "\n",
       "     Embarked_missing  \n",
       "620                 0  \n",
       "359                 0  \n",
       "512                 0  \n",
       "738                 0  \n",
       "420                 0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                 0\n",
       "SibSp               0\n",
       "Parch               0\n",
       "Fare                0\n",
       "Pclass              0\n",
       "Name                0\n",
       "Sex                 0\n",
       "Ticket              0\n",
       "Cabin               0\n",
       "Embarked            0\n",
       "Pclass_missing      0\n",
       "Name_missing        0\n",
       "Sex_missing         0\n",
       "Age_missing         0\n",
       "SibSp_missing       0\n",
       "Parch_missing       0\n",
       "Ticket_missing      0\n",
       "Fare_missing        0\n",
       "Cabin_missing       0\n",
       "Embarked_missing    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding\n",
    "\n",
    "Now that there are no missing values, convert all of the categorical features into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_and_concat_feature_train(X_train, feature_name):\n",
    "    \"\"\"\n",
    "    Helper function for transforming training data.  It takes in the full X dataframe and\n",
    "    feature name, makes a one-hot encoder, and returns the encoder as well as the dataframe\n",
    "    with that feature transformed into multiple columns of 1s and 0s\n",
    "    \"\"\"\n",
    "    # make a one-hot encoder and fit it to the training data\n",
    "    ohe = OneHotEncoder(categories=\"auto\", handle_unknown=\"ignore\")\n",
    "    single_feature_df = X_train[[feature_name]]\n",
    "    ohe.fit(single_feature_df)\n",
    "    \n",
    "    # call helper function that actually encodes the feature and concats it\n",
    "    X_train = encode_and_concat_feature(X_train, feature_name, ohe)\n",
    "    \n",
    "    return ohe, X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_and_concat_feature(X, feature_name, ohe):\n",
    "    \"\"\"\n",
    "    Helper function for transforming a feature into multiple columns of 1s and 0s. Used\n",
    "    in both training and testing steps.  Takes in the full X dataframe, feature name, \n",
    "    and encoder, and returns the dataframe with that feature transformed into multiple\n",
    "    columns of 1s and 0s\n",
    "    \"\"\"\n",
    "    # create new one-hot encoded df based on the feature\n",
    "    single_feature_df = X[[feature_name]]\n",
    "    feature_array = ohe.transform(single_feature_df).toarray()\n",
    "    ohe_df = pd.DataFrame(feature_array, columns=ohe.categories_[0], index=X.index)\n",
    "    \n",
    "    # drop the old feature from X and concat the new one-hot encoded df\n",
    "    X = X.drop(feature_name, axis=1)\n",
    "    X = pd.concat([X, ohe_df], axis=1)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = {}\n",
    "\n",
    "for categorical_feature in categorical_feature_names:\n",
    "    ohe, X_train = encode_and_concat_feature_train(X_train, categorical_feature)\n",
    "    encoders[categorical_feature] = ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_missing</th>\n",
       "      <th>Name_missing</th>\n",
       "      <th>Sex_missing</th>\n",
       "      <th>Age_missing</th>\n",
       "      <th>SibSp_missing</th>\n",
       "      <th>Parch_missing</th>\n",
       "      <th>...</th>\n",
       "      <th>F G73</th>\n",
       "      <th>F2</th>\n",
       "      <th>F33</th>\n",
       "      <th>F38</th>\n",
       "      <th>F4</th>\n",
       "      <th>G6</th>\n",
       "      <th>T</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>359</td>\n",
       "      <td>29.927982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>738</td>\n",
       "      <td>29.927982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>29.927982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1345 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Age  SibSp  Parch     Fare  Pclass_missing  Name_missing  \\\n",
       "620  27.000000    1.0    0.0  14.4542               0             0   \n",
       "359  29.927982    0.0    0.0   7.8792               0             0   \n",
       "512  36.000000    0.0    0.0  26.2875               0             0   \n",
       "738  29.927982    0.0    0.0   7.8958               0             0   \n",
       "420  29.927982    0.0    0.0   7.8958               0             0   \n",
       "\n",
       "     Sex_missing  Age_missing  SibSp_missing  Parch_missing  ...  F G73   F2  \\\n",
       "620            0            0              0              0  ...    0.0  0.0   \n",
       "359            0            1              0              0  ...    0.0  0.0   \n",
       "512            0            0              0              0  ...    0.0  0.0   \n",
       "738            0            1              0              0  ...    0.0  0.0   \n",
       "420            0            1              0              0  ...    0.0  0.0   \n",
       "\n",
       "     F33  F38   F4   G6    T    C    Q    S  \n",
       "620  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "359  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "512  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "738  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "420  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 1345 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(668, 1345)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is...a ridiculous number of columns.  How did we end up with more columns than rows?\n",
    "\n",
    "(Answer: each unique name and ticket number is now its own column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling, Again\n",
    "\n",
    "Let's run a logistic regression on our ridiculous number of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=2020, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(random_state=2020)\n",
    "logreg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened there?  This solver had no problem before\n",
    "\n",
    "Answer: it wasn't able to find the minimum with this number of steps in gradient descent\n",
    "\n",
    "Let's try a couple of stopgap measures to get the model to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=2020, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_model_more_iterations = LogisticRegression(random_state=2020, max_iter=1000)\n",
    "logreg_model_more_iterations.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=2020, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_model_more_regularization = LogisticRegression(random_state=2020, C=0.01)\n",
    "logreg_model_more_regularization.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=2020, solver='warn', tol=100, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_model_higher_tolerance = LogisticRegression(random_state=2020, tol=100)\n",
    "logreg_model_higher_tolerance.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation, Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 6))\n",
    "\n",
    "axes[0].set_title(\"More Iterations\")\n",
    "axes[1].set_title(\"More Regularization\")\n",
    "axes[2].set_title(\"More Tolerance\")\n",
    "\n",
    "plot_confusion_matrix(logreg_model_more_iterations, X_train, y_train, ax=axes[0], cmap=\"plasma\")\n",
    "plot_confusion_matrix(logreg_model_more_regularization, X_train, y_train, ax=axes[1], cmap=\"plasma\")\n",
    "plot_confusion_matrix(logreg_model_higher_tolerance, X_train, y_train, ax=axes[2], cmap=\"plasma\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78923767 0.84753363 0.80630631]\n",
      "[0.74887892 0.75336323 0.73873874]\n",
      "[0.62331839 0.62331839 0.62612613]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(logreg_model_more_iterations, X_train, y_train, cv=3))\n",
    "print(cross_val_score(logreg_model_more_regularization, X_train, y_train, cv=3))\n",
    "print(cross_val_score(logreg_model_higher_tolerance, X_train, y_train, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation, Again\n",
    "\n",
    "Let's scale all of the features, so the model isn't overly penalizing age and fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_values(X, scaler):\n",
    "    \"\"\"\n",
    "    Given a DataFrame and a fitted scaler, use the scaler to scale all of the features\n",
    "    \"\"\"\n",
    "    scaled_array = scaler.transform(X)\n",
    "    scaled_df = pd.DataFrame(scaled_array, columns=X.columns, index=X.index)\n",
    "    return scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scale_values(X_train, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_missing</th>\n",
       "      <th>Name_missing</th>\n",
       "      <th>Sex_missing</th>\n",
       "      <th>Age_missing</th>\n",
       "      <th>SibSp_missing</th>\n",
       "      <th>Parch_missing</th>\n",
       "      <th>...</th>\n",
       "      <th>F G73</th>\n",
       "      <th>F2</th>\n",
       "      <th>F33</th>\n",
       "      <th>F38</th>\n",
       "      <th>F4</th>\n",
       "      <th>G6</th>\n",
       "      <th>T</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>-2.197037e-01</td>\n",
       "      <td>0.445769</td>\n",
       "      <td>-0.488105</td>\n",
       "      <td>-0.367749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.475066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0548</td>\n",
       "      <td>-0.0548</td>\n",
       "      <td>-0.03872</td>\n",
       "      <td>-0.03872</td>\n",
       "      <td>-0.03872</td>\n",
       "      <td>-0.067166</td>\n",
       "      <td>-0.03872</td>\n",
       "      <td>2.074027</td>\n",
       "      <td>-0.299537</td>\n",
       "      <td>-1.640307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>359</td>\n",
       "      <td>-2.665810e-16</td>\n",
       "      <td>-0.473285</td>\n",
       "      <td>-0.488105</td>\n",
       "      <td>-0.501995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.104969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0548</td>\n",
       "      <td>-0.0548</td>\n",
       "      <td>-0.03872</td>\n",
       "      <td>-0.03872</td>\n",
       "      <td>-0.03872</td>\n",
       "      <td>-0.067166</td>\n",
       "      <td>-0.03872</td>\n",
       "      <td>-0.482154</td>\n",
       "      <td>3.338481</td>\n",
       "      <td>-1.640307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>4.556193e-01</td>\n",
       "      <td>-0.473285</td>\n",
       "      <td>-0.488105</td>\n",
       "      <td>-0.126142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.475066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0548</td>\n",
       "      <td>-0.0548</td>\n",
       "      <td>-0.03872</td>\n",
       "      <td>-0.03872</td>\n",
       "      <td>-0.03872</td>\n",
       "      <td>-0.067166</td>\n",
       "      <td>-0.03872</td>\n",
       "      <td>-0.482154</td>\n",
       "      <td>-0.299537</td>\n",
       "      <td>0.609642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>738</td>\n",
       "      <td>-2.665810e-16</td>\n",
       "      <td>-0.473285</td>\n",
       "      <td>-0.488105</td>\n",
       "      <td>-0.501656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.104969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0548</td>\n",
       "      <td>-0.0548</td>\n",
       "      <td>-0.03872</td>\n",
       "      <td>-0.03872</td>\n",
       "      <td>-0.03872</td>\n",
       "      <td>-0.067166</td>\n",
       "      <td>-0.03872</td>\n",
       "      <td>-0.482154</td>\n",
       "      <td>-0.299537</td>\n",
       "      <td>0.609642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>-2.665810e-16</td>\n",
       "      <td>-0.473285</td>\n",
       "      <td>-0.488105</td>\n",
       "      <td>-0.501656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.104969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0548</td>\n",
       "      <td>-0.0548</td>\n",
       "      <td>-0.03872</td>\n",
       "      <td>-0.03872</td>\n",
       "      <td>-0.03872</td>\n",
       "      <td>-0.067166</td>\n",
       "      <td>-0.03872</td>\n",
       "      <td>2.074027</td>\n",
       "      <td>-0.299537</td>\n",
       "      <td>-1.640307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1345 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age     SibSp     Parch      Fare  Pclass_missing  Name_missing  \\\n",
       "620 -2.197037e-01  0.445769 -0.488105 -0.367749             0.0           0.0   \n",
       "359 -2.665810e-16 -0.473285 -0.488105 -0.501995             0.0           0.0   \n",
       "512  4.556193e-01 -0.473285 -0.488105 -0.126142             0.0           0.0   \n",
       "738 -2.665810e-16 -0.473285 -0.488105 -0.501656             0.0           0.0   \n",
       "420 -2.665810e-16 -0.473285 -0.488105 -0.501656             0.0           0.0   \n",
       "\n",
       "     Sex_missing  Age_missing  SibSp_missing  Parch_missing  ...   F G73  \\\n",
       "620          0.0    -0.475066            0.0            0.0  ... -0.0548   \n",
       "359          0.0     2.104969            0.0            0.0  ... -0.0548   \n",
       "512          0.0    -0.475066            0.0            0.0  ... -0.0548   \n",
       "738          0.0     2.104969            0.0            0.0  ... -0.0548   \n",
       "420          0.0     2.104969            0.0            0.0  ... -0.0548   \n",
       "\n",
       "         F2      F33      F38       F4        G6        T         C         Q  \\\n",
       "620 -0.0548 -0.03872 -0.03872 -0.03872 -0.067166 -0.03872  2.074027 -0.299537   \n",
       "359 -0.0548 -0.03872 -0.03872 -0.03872 -0.067166 -0.03872 -0.482154  3.338481   \n",
       "512 -0.0548 -0.03872 -0.03872 -0.03872 -0.067166 -0.03872 -0.482154 -0.299537   \n",
       "738 -0.0548 -0.03872 -0.03872 -0.03872 -0.067166 -0.03872 -0.482154 -0.299537   \n",
       "420 -0.0548 -0.03872 -0.03872 -0.03872 -0.067166 -0.03872  2.074027 -0.299537   \n",
       "\n",
       "            S  \n",
       "620 -1.640307  \n",
       "359 -1.640307  \n",
       "512  0.609642  \n",
       "738  0.609642  \n",
       "420 -1.640307  \n",
       "\n",
       "[5 rows x 1345 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling, Again\n",
    "\n",
    "Now that the data is scaled, let's see if we can fit the model without tweaking any hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=2020, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(random_state=2020)\n",
    "logreg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation, Again\n",
    "\n",
    "Now that we are able to run a logistic regression with default hyperparameters, let's see how that performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.suptitle(\"Logistic Regression with All Features, Scaled\")\n",
    "\n",
    "plot_confusion_matrix(logreg_model, X_train, y_train, ax=ax, cmap=\"plasma\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.78026906, 0.78026906, 0.77027027])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features_cross_val_score = cross_val_score(logreg_model, X_train, y_train, cv=3)\n",
    "all_features_cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect on the training data, high 70% range on the test data...this might be overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('male', -0.7699197218790228),\n",
       " ('female', 0.7699197218790227),\n",
       " (3, -0.3860024863534165),\n",
       " ('Cabin_missing', -0.33186244955295946),\n",
       " ('B96 B98', -0.3038073061844284),\n",
       " (1, 0.2944895299974406),\n",
       " ('Allison, Master. Hudson Trevor', 0.26467255543331547),\n",
       " ('Fare', 0.23903262578311646),\n",
       " ('1601', 0.22995302698475958),\n",
       " ('Asplund, Master. Edvin Rojj Felix', 0.22653183982494968),\n",
       " ('Goldsmith, Master. Frank John William \"Frankie\"', 0.22632166542141544),\n",
       " ('Davies, Master. John Morgan Jr', 0.22470822749696986),\n",
       " ('Age', -0.22080340301463633),\n",
       " ('Allison, Miss. Helen Loraine', -0.22007910281902668),\n",
       " ('Foo, Mr. Choong', 0.21671874059799673),\n",
       " ('Bing, Mr. Lee', 0.20811003370671907),\n",
       " ('Chip, Mr. Chang', 0.20811003370671874),\n",
       " ('Allison, Mrs. Hudson J C (Bessie Waldo Daniels)', -0.20729575882619555),\n",
       " ('347082', -0.20567539884443115),\n",
       " ('Mallet, Master. Andre', 0.203479050374855),\n",
       " ('29106', 0.20181248348269518),\n",
       " ('Navratil, Master. Edmond Roger', 0.1923607234007348),\n",
       " ('113760', 0.18932628858955036),\n",
       " ('Thorneycroft, Mrs. Percival (Florence Kate White)', 0.18285120809688515),\n",
       " ('Backstrom, Mrs. Karl Alfred (Maria Mathilda Gustafsson)',\n",
       "  0.1825654926198701),\n",
       " ('Baxter, Mr. Quigg Edmond', -0.1812093633921004),\n",
       " ('2653', 0.18082496320982147),\n",
       " ('349909', -0.17710188386474887),\n",
       " ('O\\'Brien, Mrs. Thomas (Johanna \"Hannah\" Godfrey)', 0.17621182604832855),\n",
       " ('Johannesen-Bratthammer, Mr. Bernt', 0.17575267555146212),\n",
       " ('65306', 0.17575267555146212),\n",
       " ('Hakkarainen, Mrs. Pekka Pietari (Elin Matilda Dolck)', 0.1755702565025915),\n",
       " ('Thayer, Mr. John Borland', -0.1753122676528266),\n",
       " ('Nakid, Mr. Sahid', 0.17517554538619756),\n",
       " ('Navratil, Mr. Michel (\"Louis M Hoffman\")', -0.17515367441934582),\n",
       " ('Dahl, Mr. Karl Edwart', 0.1747778719233577),\n",
       " ('7598', 0.1747778719233577),\n",
       " ('2666', 0.17446890408527924),\n",
       " ('Ling, Mr. Lee', -0.1740681911242975),\n",
       " ('Niskanen, Mr. Juha', 0.17311377818307336),\n",
       " ('STON/O 2. 3101289', 0.17311377818307336),\n",
       " ('Jonsson, Mr. Carl', 0.17116961703909842),\n",
       " ('350417', 0.17116961703909842),\n",
       " ('Jussila, Mr. Eiriik', 0.17116381313353485),\n",
       " ('STON/O 2. 3101286', 0.17116381313353485),\n",
       " ('250649', 0.17103526099669028),\n",
       " ('Stranden, Mr. Juho', 0.17088555698777114),\n",
       " ('STON/O 2. 3101288', 0.17088555698777114),\n",
       " ('347077', 0.17082049715366307),\n",
       " ('PC 17611', 0.170682712093725)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(zip(X_train.columns, logreg_model.coef_[0])), key=lambda x: abs(x[1]), reverse=True)[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "Let's try out some different regularization penalties to see if we can improve the test data score a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old: [0.78026906 0.78026906 0.77027027]\n",
      "New: [0.78026906 0.78475336 0.76576577]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(random_state=2020, C=0.1)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Old:\", all_features_cross_val_score)\n",
    "print(\"New:\", cross_val_score(logreg_model, X_train, y_train, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like it doesn't make a difference\n",
    "\n",
    "Try a little less regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old: [0.78026906 0.78026906 0.77027027]\n",
      "New: [0.78026906 0.78026906 0.77027027]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(random_state=2020, C=0.5)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Old:\", all_features_cross_val_score)\n",
    "print(\"New:\", cross_val_score(logreg_model, X_train, y_train, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same or worse\n",
    "\n",
    "Try a little more regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old: [0.78026906 0.78026906 0.77027027]\n",
      "New: [0.78475336 0.78475336 0.76576577]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(random_state=2020, C=0.05)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Old:\", all_features_cross_val_score)\n",
    "print(\"New:\", cross_val_score(logreg_model, X_train, y_train, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also worse.  It looks like the default C value is pretty optimal for this solver.\n",
    "\n",
    "Let's try some other solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old: [0.78026906 0.78026906 0.77027027]\n",
      "New: [0.78026906 0.78026906 0.77027027]\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(random_state=2020, solver=\"liblinear\")\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Old:\", all_features_cross_val_score)\n",
    "print(\"New:\", cross_val_score(logreg_model, X_train, y_train, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little slower, but no major difference in the scores.  Let's try adding some more regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old: [0.78026906 0.78026906 0.77027027]\n",
      "New: [0.78026906 0.78475336 0.76126126]\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(random_state=2020, solver=\"liblinear\", C=0.01)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Old:\", all_features_cross_val_score)\n",
    "print(\"New:\", cross_val_score(logreg_model, X_train, y_train, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting better.  Try a different type of penalty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old: [0.78026906 0.78026906 0.77027027]\n",
      "New: [0.77130045 0.82511211 0.7972973 ]\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(random_state=2020, solver=\"liblinear\", penalty=\"l1\")\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Old:\", all_features_cross_val_score)\n",
    "print(\"New:\", cross_val_score(logreg_model, X_train, y_train, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly better average here.  Try adding some more regularization with L1 penalty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old: [0.78026906 0.78026906 0.77027027]\n",
      "New: [0.76681614 0.8206278  0.7972973 ]\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(random_state=2020, solver=\"liblinear\", penalty=\"l1\", C=0.01)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Old:\", all_features_cross_val_score)\n",
    "print(\"New:\", cross_val_score(logreg_model, X_train, y_train, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, the default regularization strength seems pretty good.  Double-check the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = LogisticRegression(random_state=2020, solver=\"liblinear\", penalty=\"l1\")\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.suptitle(\"Logistic Regression with All Features (Scaled, Hyperparameters Tuned)\")\n",
    "\n",
    "plot_confusion_matrix(logreg_model, X_train, y_train, ax=ax, cmap=\"plasma\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably still overfitting, but let's call this our final model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Evaluation\n",
    "\n",
    "Now that we have a final model, run X_test through all of the preprocessing steps so we can evaluate the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_no_transformations = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add missing indicators\n",
    "X_test = add_missing_indicator_columns(X_test, indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate out values for imputation\n",
    "X_test_numeric = X_test[numeric_feature_names]\n",
    "X_test_categorical = X_test[categorical_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values\n",
    "X_test_numeric = impute_missing_values(X_test_numeric, numeric_imputer)\n",
    "X_test_categorical = impute_missing_values(X_test_categorical, categorical_imputer)\n",
    "X_test_imputed = pd.concat([X_test_numeric, X_test_categorical], axis=1)\n",
    "X_test = X_test.drop(numeric_feature_names + categorical_feature_names, axis=1)\n",
    "X_test = pd.concat([X_test_imputed, X_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode categorical data\n",
    "for categorical_feature in categorical_feature_names:\n",
    "    X_test = encode_and_concat_feature(X_test, categorical_feature, encoders[categorical_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale values\n",
    "X_test = scale_values(X_test, scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a model with the relevant hyperparameters, fit, and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7847533632286996"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = LogisticRegression(random_state=2020, solver=\"liblinear\", penalty=\"l1\")\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "final_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Dummy Model</td>\n",
       "      <td>0.591928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Simple Linear Regression Model</td>\n",
       "      <td>0.623318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Final Model</td>\n",
       "      <td>0.784753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Mean Accuracy\n",
       "Dummy Model                          0.591928\n",
       "Simple Linear Regression Model       0.623318\n",
       "Final Model                          0.784753"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_scores_dict = {\n",
    "    \"Mean Accuracy\": [\n",
    "        dummy_model.score(X_test, y_test), \n",
    "        simple_logreg_model.score(X_test_no_transformations[[\"SibSp\", \"Parch\", \"Fare\"]], y_test),\n",
    "        final_model.score(X_test, y_test)\n",
    "    ]\n",
    "}\n",
    "final_scores_df = pd.DataFrame(final_scores_dict, index=[\"Dummy Model\", \"Simple Linear Regression Model\", \"Final Model\"])\n",
    "final_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final comparison of confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 6), sharey=True)\n",
    "\n",
    "fig.suptitle(\"Confusion Matrix Comparison\")\n",
    "\n",
    "axes[0].set_title(\"Dummy Model\")\n",
    "axes[1].set_title(\"Simple Model\")\n",
    "axes[2].set_title(\"Final Tuned Model\")\n",
    "\n",
    "plot_confusion_matrix(dummy_model, X_test, y_test, ax=axes[0], cmap=\"plasma\")\n",
    "plot_confusion_matrix(simple_logreg_model, X_test_no_transformations[[\"SibSp\", \"Parch\", \"Fare\"]], y_test, ax=axes[1], cmap=\"plasma\")\n",
    "plot_confusion_matrix(final_model, X_test, y_test, ax=axes[2], cmap=\"plasma\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
